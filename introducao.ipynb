{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao TensorFlow\n",
    "\n",
    "\n",
    "<img src=\"img/tensorflow.png\" width=150px>\n",
    "\n",
    "Ao longo desta aula, você aplicará seus conhecimentos de redes neurais em conjuntos de dados reais usando o [TensorFlow](https://www.tensorflow.org), uma biblioteca de código aberto de Deep Learning criada pela Google. Você usará o TensorFlow para classificar imagens do conjunto de dados notMNIST - um conjunto de imagens em inglês de A até J. Você pode ver alguns exemplos abaixo.\n",
    "\n",
    "<img src=\"img/notmnist.png\" width=400px>\n",
    "\n",
    "Seu objetivo será detectar automaticamente a letra baseada na imagem do conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instalação\n",
    "\n",
    "Um arquivo de ambiente com todos os pacotes necessários para o acompanhamento da aula foi criado e está no mesmo repositório que este notebook (procure por `tf_intro.yaml`). Use o comando abaixo para criar o ambiente a partir dele:\n",
    "\n",
    "`conda env create -f tf_intro.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após criar e entrar no ambiente `tf_intro`, execute a célula abaixo para garantir que tudo está instalado corretamente. O output deve ser \"Ola, mundo!\". Não se preocupe em entender o que está acontecendo, explicações serão dadas ao longo do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Ola, mundo!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello_constant = tf.constant('Ola, mundo!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \"Olá, mundo\" do TensorFlow\n",
    "\n",
    "Nesta seção, vamos analisar o script que foi executado na célula acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "No TensorFlow, os objetos não são salvos em integers, floats ou strings. estes valores são encapsulados em um objeto chamado tensor. No caso de `hello_constant = tf.constant('Ola, mundo!')`, `hello_constant` é um tensor string de 0 dimensões, mas os tensores podem ter uma variedade de tamanhos, como exposto abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A é um tensor int32 de 0 dimensões\n",
    "A = tf.constant(1234)\n",
    "\n",
    "# B é um tensor int32 de 1 dimensão\n",
    "B = tf.constant([123, 456, 789])\n",
    "\n",
    "# C é um tensor int32 de 2 dimensões\n",
    "C = tf.constant([[123, 456, 789], [222, 333, 444]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`tf.constant`**](https://www.tensorflow.org/api_docs/python/tf/constant) é uma das diversas operações do TensorFlow que usaremos neste notebook. O tensor retornado por [**`tf.constant`**](https://www.tensorflow.org/api_docs/python/tf/constant) é o que chamamos de tensor constante, pois seu valor nunca muda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessão\n",
    "\n",
    "A API do TensorFlow é construída em volta da ideia de um grafo computacional, um modo de visualizar processos matemáticos que é discutido no repositório do MiniFlow **(incluir link para repo)**. A figura abaixo ilustra o código do \"Olá, mundo\" transformado em um grafo:\n",
    "\n",
    "<img src=\"img/session.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma \"Sessão do TensorFlow\", como mostrada acima, é um abiente para rodar um grafo. A sessão é responsável por alocar as operações para as GPU(s) e/ou CPU(s), incluindo máquinas remotas. Vamos executar o \"Olá, mundo\" mais uma vez e logo depois entender como funciona a sessão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Ola, mundo!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello_constant = tf.constant('Ola, mundo!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código cria o tensor `hello_constant` nas linhas iniciais. O próximo passo é avaliar o tensor na sessão.\n",
    "\n",
    "O código cria uma instância de sessão, `sess`, usando [**`tf.Session`**](https://www.tensorflow.org/api_docs/python/tf/Session). A função [**`sess.run()`**](https://www.tensorflow.org/api_docs/python/tf/Session#run) então avalia o tensor e retorna os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Input\n",
    "\n",
    "Na seção anterior, passamos um tensor por uma sessão e ele retornou um resultado. E se quisermos usar algo não constante? Aqui é onde a função [**`tf.placeholder()`**](https://www.tensorflow.org/api_docs/python/tf/placeholder) e o `feed_dict` aparecem. Nesta seção, apresentaremos o básico sobre como introduzir dados no TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder()\n",
    "\n",
    "Infelizmente, não é possível alocar `x` para o conjunto de dados e colocar isso no TensorFlow, porque com o tempo você irá querer que o seu modelo receba diferentes conjuntos de dados com diferentes parâmetros. Para isso, você precisará do [**`tf.placeholder()`**](https://www.tensorflow.org/api_docs/python/tf/placeholder)!\n",
    "\n",
    "[**`tf.placeholder()`**](https://www.tensorflow.org/api_docs/python/tf/placeholder) retorna um tensor que pega o valor dos dados passados para a função [**`tf.session.run()`**](https://www.tensorflow.org/api_docs/python/tf/Session#run), permitindo que você decida o input logo antes da sessão rodar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feed_dict\n",
    "\n",
    "O parâmetro `feed_dict` é usado na [**`tf.session.run()`**](https://www.tensorflow.org/api_docs/python/tf/Session#run) para alocar o tensor placeholder. O exemplo abaixo mostra o tensor `x` recebendo a string `Ola, mundo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Ola, mundo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível alocar mais de um tensor usando o `feed_dict`, como feito abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    outpupt = sess.run(x, feed_dict={x: 'Teste', y: 123, z: 45.67})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso os dados passados para o `feed_dict` não combinem com o tipo do tensor e não possam ser lançados no tipo do tensor, você obterá o erro \"`ValueError: invalid literal for`...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Matemática com TensorFlow\n",
    "\n",
    "Conseguir o input é ótimo, mas agora precisamos usá-lo. Nesta seção, usaremos as funções matemáticas mais conhecidas (adição, subtração, multiplicação e divisão) com tensores. Existem muitas outras funções matemáticas que podem ser encontradas na [documentação](https://www.tensorflow.org/api_docs/python/math_ops/) do Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição\n",
    "\n",
    "Começaremos com a função de adição. A função [**`tf.add()`**](https://www.tensorflow.org/api_docs/python/tf/add) faz exatamente o que esperamos que ela faça: recebe dois números, dois tensores ou um de cada, e retorna a soma deles como um tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "x = tf.add(5, 2)    # Retorna 7\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subratação, multiplicação e divisão\n",
    "\n",
    "Assim como a função de adição, as funções de subratação, multiplicação e divisão são bastante intuitivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "75\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = tf.subtract(15, 5)    # Retorna 10\n",
    "b = tf.multiply(15, 5)    # Retorna 75\n",
    "c = tf.div(15, 5)         # Retorna 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b))\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo tipos\n",
    "\n",
    "Pode ser necessário converter tipos para fazer alguns operadores trabalharem juntos. Por exemplo, o código `tf.subtract(tf.constant(2.0), tf.constant(1))` falha ao ser executad.\n",
    "\n",
    "Isso acontece pois `1` é um interger e a constante `2.0` é um ponto flutuante. A operação `subtract` espera que eles combinem.\n",
    "\n",
    "Em casos como este, você pode tanto garantir que os dados sejam sempre do mesmo tipo quanto mudar o tipo de um determinado valor. Neste caso, converter `2.0` para um interger antes de subtrair irá gerar o resultado certo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo\n",
    "\n",
    "Na célula a seguir, usaremos o TensorFlow para imprimir o resultado da expressão numérica `10 / 2 - 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "result = tf.subtract(tf.div(x, y), 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Função linear no TensorFlow\n",
    "\n",
    "A operação ais comum nas redes neurais é calcular a combinação linear de inputs, pesos e vieses. Para lembrar, nós podemos escrever o output da operação linear como\n",
    "\n",
    "$$\n",
    "y = xW + b\n",
    "$$\n",
    "\n",
    "Aqui, **W** é a matriz dos pesos conectando duas camadas. O output **y**, o input **x** e os vieses **b** são todos vetores.\n",
    "\n",
    "O objetivo de treinar uma rede neural é modificar os pesos e vieses para prever os rótulos de modo mais eficiente. A fim de usar pesos e viés, você precisará de um tensor que pode ser modificado. Isso elimina o [**`tf.placeholder()`**](https://www.tensorflow.org/api_docs/python/tf/placeholder) e o [**`tf.constant()`**](https://www.tensorflow.org/api_docs/python/tf/constant), uma vez que esses tensores não podem ser modificados. Aqui é onde aparece a classe [**`tf.Variable`**](https://www.tensorflow.org/api_docs/python/tf/Variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Variable()\n",
    "\n",
    "A classe [**`tf.Variable`**](https://www.tensorflow.org/api_docs/python/tf/Variable) cria um tensor com um valor inicial que pode ser modificado, tal como uma variável comum do Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse tensor guarda o estado em ua sessão, então é necessário inicializar o estado do tensor manualmente. Usaremos a função [**`tf.global_variables_initializer()`**](https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer) para inicializar o estado de todos os tensores Variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao chamar [**`tf.global_variables_initializer()`**](https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer), a função retorna uma operação que irá inicializar todas as variáveis TensorFlow do grafo. Chama-se a operação usando uma sessão para inicializar todas as variáveis, como mostrado acima. Usar a classe [**`tf.Variable`**](https://www.tensorflow.org/api_docs/python/tf/Variable) permite que mudemos os pesos e o viés, mas os alores iniciais precisam ser escolhidos.\n",
    "\n",
    "Inicializar os pesos com números aleatórios a partir de uma distribuição normal é uma boa prática. Randomizar os pesos ajuda o modelo a não ficar preso sempre no mesmo lugar toda vez que for treinado.\n",
    "\n",
    "De modo similar, escolher os pesos de uma distribuição normal previne que um peso se sobreponha aos outros. Usaremos a função [**`tf.truncated_normal()`**](https://www.tensorflow.org/api_docs/python/tf/truncated_normal) para gerar números aleatórios a partir de uma distribuição normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.truncated_normal()\n",
    "\n",
    "A função [**`tf.truncated_normal()`**](https://www.tensorflow.org/api_docs/python/tf/truncated_normal) retorna um tensor com valores aleatórios vindos de uma distribuição normal cuja magnitude é de não mais que 2 desvios padrão da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que os pesos já auxiliam o modelo a não se prender, não é necessário randomizar também o viés. Vamos usar a solução mais simples que é definir o viés como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.zeros()\n",
    "\n",
    "A função [**`tf.zeros()`**](https://www.tensorflow.org/api_docs/python/tf/zeros) retorna um tensor composto de zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Neste exercício, você deve classificar números `0`, `1` e `2` escritos a mão do conjunto de dados MNIST usando o TensorFlow. A figura abaixo mostra uma pequena amostra dos dados que serão usados para o treinamento. Repare que alguns dos `1` foram escritos com uma serifa no topo e com ângulos diferentes. As similaridades e diferenças terão um papel importante na definição dos pesos do modelo.\n",
    "\n",
    "<img src='img/mnist_012.png'>\n",
    "\n",
    "As imagens abaixo são os pesos treinados para cada rótulo (`0`, `1` e `2`, da esquerda para a direita). Os pesos mostram as propriedades únicas de cada dígito que eles encontraram.\n",
    "\n",
    "<img src='img/weights_012.png' width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siga as instruções abaixo para treinar seus próprios pesos:\n",
    "1. Abra o arquivo funcao_linear.py\n",
    "     1. Implemente `gerar_pesos` de modo que retorne um `tf.Variable` com pesos aleatórios\n",
    "     2. Implemente `gerar_vies` de modo que retorne um `tf.Variable` preenchido com zeros.\n",
    "     3. Implemente `linear`.\n",
    "2. Inicialize todos os pesos antes de executar a célula abaixo.\n",
    "\n",
    "**Nota**: uma vez que $xW$ em $xW + b$ é uma multiplicação de matrizes, é necessário usar a função [**`tf.matmul()`**](https://www.tensorflow.org/api_docs/python/tf/matmul) ao invés de [**`tf.multiply()`**](https://www.tensorflow.org/api_docs/python/tf/multiply). Não se esqueça que a ordem é importante na multiplicação de matrizes, então `tf.matmul(a, b)` não é a mesma coisa que `tf.matmul(b, a)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Loss: 5.477291107177734\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from funcao_linear import gerar_pesos, gerar_vies, linear\n",
    "from auxiliar import mnist_features_labels\n",
    "\n",
    "# Definição do número de atributos e de rótulos\n",
    "n_features = 28 * 28    # Imagens do MNIST têm dimensões 28x28\n",
    "n_labels = 3            # Apenas os três primeiros rótulos (0, 1 e 2)\n",
    "\n",
    "# Atributos e rótulos\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Chamar as funções implementadas em funcao_linear.py\n",
    "w = gerar_pesos(n_features, n_labels)\n",
    "b = gerar_vies(n_labels)\n",
    "logits = linear(features, w, b)\n",
    "\n",
    "# Obter dados de treinamento\n",
    "X, y = mnist_features_labels(n_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # TODO: Inicialize as variáveis na sessão\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    # Entropia cruzada\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), \n",
    "                                   reduction_indices=1)\n",
    "    \n",
    "    # Perda\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # Taxa de aprendizado\n",
    "    learning_rate = 0.08\n",
    "    \n",
    "    # Gradiente descendente\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    # Executar otimizador e obter perda\n",
    "    _, l = sess.run([optimizer, loss], feed_dict={features: X, labels:y})\n",
    "\n",
    "# Imprimir perda\n",
    "print('Loss: {}'.format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Softmax no TensorFlow\n",
    "\n",
    "A função softmax comprime os inputs, normalmente chamados de **logits**, que são números entre 0 e 1 e também normaliza os outputs de modo que todos eles somados resultem em 1. Isso significa que o output da função softmax é equivalente Pa distribuição de probabilidade entre categorias. É a função perfeita para ser usada como ativação de output em uma rede prevendo múltiplas classes.\n",
    "\n",
    "<img src='img/softmax_input_output.png' width=500px>\n",
    "\n",
    "Estamos usando o TensorFlow para construir redes neurais e, convenientemente, existe uma função para calcular o softmax. A função [**`tf.nn.softmax()`**](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) recebe os logits e retorna as ativações softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6590012  0.24243298 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "logit_data = [2.0, 1.0, 0.1]\n",
    "\n",
    "logits = tf.placeholder(tf.float32)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entropia cruzada no TensorFlow\n",
    "\n",
    "Como visto anteriormente no curso, a entropia cruzada pode ser usada como função de custo em classificações codificadas one-hot. \n",
    "\n",
    "<img src='img/cross_entropy_diagram.png' width=500px>\n",
    "\n",
    "A partir da figura acima, conclue-se que é possível criar uma função de entropia cruzada no TensorFlow. Para tanto, são necessárias duas funções: [**`tf.reduce_sum()`**](https://www.tensorflow.org/api_docs/python/tf/reduce_sum) e [**`tf.log()`**](https://www.tensorflow.org/api_docs/python/tf/log)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_sum()\n",
    "\n",
    "A função [**`tf.reduce_sum()`**](https://www.tensorflow.org/api_docs/python/tf/reduce_sum) soma todos os números de uma array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reduce_sum([1, 2, 3, 4, 5])    # Retorna 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.log()\n",
    "\n",
    "A função [**`tf.log()`**](https://www.tensorflow.org/api_docs/python/tf/log) retorna o log natural de um número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.log(100.0)    # Retorna 4.60517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação\n",
    "\n",
    "Na célula abaixo, vamos implementar a função de entropia cruzada usando TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667497\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={softmax: softmax_data, \n",
    "                                             one_hot: one_hot_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Minibatch no TensorFlow\n",
    "\n",
    "Minibatch (miniloteamento em português) é a técnica utilizada para treinar em subconjuntos do conjunto de dados ao invés de usar todos os dados de uma vez. Isso permite treinar um modelo mesmo se o computador não tiver a memória para guardar todo o conjunto de dados.\n",
    "\n",
    "O minibatch é computacionalmente ineficiente, uma vez que você não pode calcular a perda simultaneamente através de todas as amostras. No entanto, esse é um pequeno preço a se pagar para poder pelo menos rodar um modelo.\n",
    "\n",
    "Essa técnica também é útil ao ser combinada com a SGD. A ideia é embaralhar aleatoriamente os dados no começo de cada época, então criar os minilotes. Para cada minilote, treina-se os pesos da rede com gradiente descendente. Uma vez que os lotes são aleatórios, está sendo realizado uma SGD com cada lote.\n",
    "\n",
    "Vamos olhar o conjunto de dados do MNIST com pesos e viés para ver se sua máquina consegue lidar com ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "n_input = 28 * 28    # MNIST data input (image shape: 28x28)\n",
    "n_classes = 10       # MNIST total classes (0-9 digits)\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/datasets/ud730/mnist', \n",
    "                                  one_hot=True)\n",
    "\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células a seguir, vamos calcular quantos bytes de memória as variáveis `train_features`, `train_labels`, `weights` e `bias` ocupam. Caso você não saiba quanta memória um float32 exige, recomendamos a leitura [deste link](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "variables = [train_features, train_labels, weights, bias]\n",
    "\n",
    "for variable in variables:\n",
    "    print(variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: 172480000 bytes\n",
      "train_features: 2200000 bytes\n",
      "train_features: 31360 bytes\n",
      "train_features: 40 bytes\n",
      "Total: 174711400 bytes\n"
     ]
    }
   ],
   "source": [
    "train_features_size = 4 * variables[0].shape[0] * variables[0].shape[1]\n",
    "print('train_features: {} bytes'.format(train_features_size))\n",
    "\n",
    "train_labels_size = 4 * variables[1].shape[0] * variables[1].shape[1]\n",
    "print('train_features: {} bytes'.format(train_labels_size))\n",
    "\n",
    "weights_size = 4 * variables[2].shape[0] * variables[2].shape[1]\n",
    "print('train_features: {} bytes'.format(weights_size))\n",
    "\n",
    "bias_size = 4 * variables[3].shape[0]\n",
    "print('train_features: {} bytes'.format(bias_size))\n",
    "\n",
    "print('Total: {} bytes'.format(train_features_size + train_labels_size \n",
    "                               + weights_size + bias_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O total de espaço na memória necessário para os inputs, pesos e viés é de aproximadamente 174 MB, o que não é muito. É possível treinar esse conjunto de dados na maioria dos CPUs e GPUs. Mas conjuntos de dados maiores que aparecerão no futuro serão medidos em GB ou até mais. É possível comprar mais memória, mas isso é caro. Uma placa de vídeo (GPU) Titan X com 12 GB de memória custa mais de R$ 4.000,00. Ao invés disso, para rodar modelos grandes na sua máquina, utiliza-se o miniloteamento.\n",
    "\n",
    "Infelizmente, muitas vezes não é possível dividir os dados em lotes de tamanhos exatamente iguais. Por exemplo, imagine que você quer criar lotes de tamanho 128 cada um com um conjunto de dados com 1000 amostras. Uma vez que 128 não divide 1000 sem deixar resto, você terminará o processo com 7 lotes de 128 amostras e 1 lote com 104 amostrar (7 * 128 + 1 * 104 = 1000).\n",
    "\n",
    "Neste caso, o tamanho das amostras varia, então é importante se aproveitar da função do TensorFlow [**`tf.placeholder()`**](https://www.tensorflow.org/api_docs/python/tf/placeholder) para receber os tamanhos variáveis dos lotes.\n",
    "\n",
    "Continuando com o exemplo do MNIST, se cada amostra tiver 784 características (`n_input = 28 * 28`) e 10 possíveis rótulos (`n_classes = 10`), as dimensões de `features` seriam `[None, n_input]` e de `labels` seriam `[None, n_classes]`. \n",
    "\n",
    "A dimensão `None` é um marcador de posição para o tamanho do lote. Na hora de executar, o TensorFlow aceita qualquer tamanho de lote maior que 0. A configuração abaixo permite que você forneça `features` e `labels` para o modelo seja com lotes de 128 amostras, seja com lote lotes de 104 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fixar toda a ideia, vamos criar um exemplo na célula abaixo e calcular quantos lotes teremos e qual será o tamanho do último lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de lotes: 391\n",
      "Tamanho do ultimo lote: 80\n"
     ]
    }
   ],
   "source": [
    "# features.shape = (50000, 400)\n",
    "# labels.shape = (50000, 10)\n",
    "# batch_size = 128\n",
    "\n",
    "print('Quantidade de lotes: {}'.format(50000 // 128 + 1))\n",
    "print('Tamanho do ultimo lote: {}'.format(50000 % 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Neste exercício, você deve implementar a função `batches` no arquivo mini_batches.py e testá-lo na célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['F11', 'F12', 'F13', 'F14'],\n",
      "   ['F21', 'F22', 'F23', 'F24'],\n",
      "   ['F31', 'F32', 'F33', 'F34']],\n",
      "  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n",
      " [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"
     ]
    }
   ],
   "source": [
    "from mini_batches import batches\n",
    "from pprint import pprint\n",
    "\n",
    "# 4 samples of features\n",
    "example_features = [['F11', 'F12', 'F13', 'F14'],\n",
    "                    ['F21', 'F22', 'F23', 'F24'],\n",
    "                    ['F31', 'F32', 'F33', 'F34'],\n",
    "                    ['F41', 'F42', 'F43', 'F44']]\n",
    "\n",
    "# 4 samples of labels\n",
    "example_labels = [['L11', 'L12'],\n",
    "                  ['L21', 'L22'],\n",
    "                  ['L31', 'L32'],\n",
    "                  ['L41', 'L42']]\n",
    "\n",
    "# pprint imprime estruturas de dados como arrays 2D para tornar a leitura\n",
    "# mais fácil\n",
    "pprint(batches(3, example_features, example_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você se certificou que a função `batches` foi implementada corretamente, utilize-a para alimentar um modelo linear com rótulos e atributos do MNIST. Para isso, você deve configurar o tamanho do lote e rodar o otimizador por todos os lotes com a função implementada. O tamanho do lote recomendado é 128 (caso tenha restrições de memória, sinta-se livre para mudar o tamanho dos lotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/datasets/ud730/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Test accuracy: 0.09470000118017197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from funcao_linear import linear\n",
    "from mini_batches import batches\n",
    "\n",
    "n_features = 28 * 28\n",
    "n_labels = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/datasets/ud730/mnist', \n",
    "                                  one_hot=True)\n",
    "\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "X, y = mnist_features_labels(n_labels)\n",
    "\n",
    "# TODO: Configure o tamanho do mini-lote\n",
    "batch_size = 128\n",
    "assert batch_size is not None, 'Configure batch_size'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # TODO: Treinar o otimizador em todos os mini-lotes\n",
    "    batches = batches(batch_size, train_features, train_labels)\n",
    "    for batch_features, batch_labels in batches:\n",
    "        sess.run(optimizer, feed_dict={features: batch_features,\n",
    "                                       labels: batch_labels})\n",
    "    \n",
    "    test_accuracy = sess.run(accuracy, feed_dict={features: test_features,\n",
    "                                                  labels: test_labels})\n",
    "\n",
    "# Imprimir perda\n",
    "print('Test accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia é baixa, mas você já sabe que pode treinar no conjunto de dados mais de uma vez. É possível treinar um modelo usando o conjunto de dados múltiplas vezes. Trataremos deste assunto na próxima sessão, onde falaremos sobre épocas (epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Épocas no TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
